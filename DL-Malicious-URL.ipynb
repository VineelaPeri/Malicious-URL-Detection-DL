{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection and Classification of Malicious URLS with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL is the abbreviation of Uniform Resource Locator, which is the global address of documents and other resources on the World Wide Web. A URL has two main components: (i) protocol identifier, it indicates what protocol to use, (ii) resource name, it specifies the IP address or the domain name where the resource is located. The protocol identifier and the resource name are separated by a colon and two forward slashes. An example is shown in Figure 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"URL.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning approaches, use a set of URLs as training data, and based on the statistical properties, learn a prediction function to classify a URL as malicious or benign. One would need to extract suitable features based on some principles or heuristics to obtain a good feature representation of the URL. This may include lexical features (statistical properties of the URL string, bag of words, n-gram, etc.), host based features (WHOIS info, geo-location properties of the host, etc.). The quality of feature representation of the URLs is critical to the quality of the resulting malicious URL predictive model learned by machine learning.  Finally, using the training data with the appropriate feature representation, the next step in building the prediction model is the actual training of the model. There are plenty of classification algorithms can be directly used over the training data (Naive Bayes, Support Vector Machine, Logistic Regression, etc.). While the above approaches have shown successful performance, they suffer from several limitations, particularly in the context of very large scale Malicious URL Detection: \n",
    "\n",
    "(i) Inability to effectively capture semantic or sequential patterns: They fail to effectively capture the sequence in which words (or characters) appear in the URL String; \n",
    "\n",
    "(ii) Require substantial manual feature engineering important features for the task (e.g. which statistical properties of the URL to use, what type of n-gram features would be better, etc.). \n",
    "\n",
    "(iii) Inability to handle unseen features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the above issues, I would like to experiment Deep Learning based solution for Malicious URL Detection. Deep Learning uses layers of stacked nonlinear projections in order to learn representations of multiple levels of abstraction. It has demonstrated state of the art performance in many applications (computer vision, speech recognition, natural language processing, etc.). In particular, Convolutional Neural Networks (CNNs) have shown promising performance for text classification in recent years. Following their success, \n",
    "\n",
    "I am experimenting the use of CNNs to learn a URL embedding for Malicious URL Detection. A URL string is used as input and applies CNNs to both characters in the URL to learn patterns and distinguish malicious and benign. For Character-level CNNs we first identify unique characters in the training corpus, and represent each character as a vector. Using this, the entire URL (a sequence of characters) is converted to a matrix representation, on which convolution can be applied. Character CNNs identify important information from certain groups of characters appearing together which could be indicative of maliciousness. I first implement a simple LSTM architecture. Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Modules Required to run this code </font>\n",
    "Numpy\n",
    "\n",
    "Keras.\n",
    "\n",
    "Pandas.\n",
    "\n",
    "Scikit Learn.\n",
    "\n",
    "Tensorflow.\n",
    "\n",
    "Utils\n",
    "\n",
    "Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "from string import printable\n",
    "from sklearn import model_selection\n",
    "import matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "#import gensim\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda, Flatten\n",
    "from keras.layers import merge\n",
    "from keras.layers import Input, ELU, LSTM, Embedding, Convolution2D, MaxPooling2D, \\\n",
    "BatchNormalization, Convolution1D, MaxPooling1D, concatenate, merge, Conv1D\n",
    "from keras.layers import TimeDistributed, Bidirectional\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "tf.python.control_flow_ops = tf\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='blue'> Dataset </font>\n",
    "I am using a sample dataset of 10K URL. The data folder also has 1000, 500,000 sample CSV. This file exists in the data folder. There are also 2 other dataset with 1K and 100K that can be executed for test and training purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.facebook-log1in.com/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://getir.net/yg4t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://crosscitydental.com/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.tenttrails.com/jscripts/product.js</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://103.224.193.105/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             url  malicious\n",
       "0                http://www.facebook-log1in.com/          1\n",
       "1                          http://getir.net/yg4t          1\n",
       "2                    http://crosscitydental.com/          0\n",
       "3  http://www.tenttrails.com/jscripts/product.js          0\n",
       "4                        http://103.224.193.105/          0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "%matplotlib inline\n",
    "cwd = os.getcwd()#To access the path of current working directory\n",
    "path=cwd+\"/\"+\"data\"+\"/\"\n",
    "data=pd.read_csv(path +\"sample_10.csv\")\n",
    "data.head()\n",
    "df=data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Preprocessing Raw URLs </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Deep Learning approach, no hand-crafted features nor API queries are needed. However, limited pre-processing of the raw URLs is still necessary. The raw URL string needs to be split into \"words\". Very easily done, every single character can be considered a \"word\". In addition, each character has to be expressed as unique integer. This requires building a dictionary first. A short cut can be considering Python's 100 printable characters. (only relevant for English language). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ..., 25 23 77]\n",
      " [ 0  0  0 ..., 17  5 30]\n",
      " [ 0  0  0 ..., 25 23 77]\n",
      " ..., \n",
      " [ 0  0  0 ..., 25 23 77]\n",
      " [ 0  0  0 ..., 27 31 77]\n",
      " [ 0  0  0 ..., 25 30 83]]\n",
      "Matrix dimensions of X:  (9998, 100) Vector dimension of target:  (9998,)\n"
     ]
    }
   ],
   "source": [
    "# Initial Data Preparation URL\n",
    "\n",
    "# Step 1: Convert raw URL string in list of lists where characters that are contained in \"printable\" are stored encoded as integer \n",
    "url_int_tokens = [[printable.index(x) + 1 for x in url if x in printable] for url in df.url]\n",
    "\n",
    "# Step 2: Cut URL string at max_len or pad with zeros if shorter\n",
    "max_len=100\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)\n",
    "print(X)\n",
    "# Step 3: Extract labels form df to numpy array\n",
    "target = np.array(df.malicious)\n",
    "\n",
    "print('Matrix dimensions of X: ', X.shape, 'Vector dimension of target: ', target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above pre-processing would map a URL as below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 30, 30, 26, 78, 77, 77, 33, 33, 33, 76, 16, 11, 13, 15, 12, 25, 25, 21, 75, 22, 25, 17, 2, 19, 24, 76, 13, 25, 23, 77]\n"
     ]
    }
   ],
   "source": [
    "test_url = 'http://www.facebook-log1in.com/'\n",
    "print([printable.index(x)+1 for x in test_url if x in printable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "The next step is to learn an embedding that captures the properties about the sequence in which the characters appear in a URL. We set the length of the sequence L1 = 100 characters. URLs longer than 100 characters would get truncated from the 100th character, and any URLs shorter than 100 would get padded till their lengths reached 100. A domain length distribution of my dataset shows majority if url have length under 100. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x139006160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domainlengths=df[\"url\"].apply(lambda x: len(x))\n",
    "plt.hist(domainlengths,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above histogram shows that in this dataset majority of the URL have the 100 so i set a max_len to 100. Any URL vector that has less than 100 will be paaded with extra 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding layer and need for it. \n",
    "In addition to the pre-processing I use an embedding layer. The Embedding can be implemented in mutliple ways and I experiment with the default Keras implementation of Tensorflow word2vec\n",
    "\n",
    "One-hot encoded vectors are high-dimensional and sparse. Let’s assume that we are doing Natural Language Processing (NLP) and have a dictionary of 2000 words. This means that, when using one-hot encoding, each word will be represented by a vector containing 2000 integers. And 1999 of these integers are zeros. In a big dataset this approach is not computationally efficient.\n",
    "\n",
    "The vectors of each embedding get updated while training the neural network. If you have seen the image at the top of this post you can see how similarities between words can be found in a multi-dimensional space. This allows us to visualize relationships between words, but also between everything that can be turned into a vector through an embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Additional verbose logging for the Deep learning models\n",
    "The below method is used to print layers within the three individual netowrks implemented in this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERAL get layer dimensions for any model!\n",
    "def print_layers_dims(model):\n",
    "    l_layers = model.layers\n",
    "    # Note None is ALWAYS batch_size\n",
    "    for i in range(len(l_layers)):\n",
    "        print(l_layers[i])\n",
    "        print('Input Shape: ', l_layers[i].input_shape, 'Output Shape: ', l_layers[i].output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Training and Evaluation </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split for train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple Cross-Validation: Split the data set into training and test data\n",
    "X_train, X_test, target_train, target_test = model_selection.train_test_split(X, target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Input and Output Layers of Neural Networks </font>\n",
    "\n",
    "I would like to show what the input and output layers implemented in this project would look like.  The very first initial layer is always an input layer where you define the initial input shape (here initial 100 characters of the URL). \n",
    "\n",
    "\n",
    "Next is the Embedding layer that is built upon the Input layer. \n",
    "\n",
    "<img src=\"embeddedlayer.png\">\n",
    "\n",
    "This general process of \"chaining\" would continue...\n",
    "\n",
    "<img src=\"chainlayer.png\">\n",
    "\n",
    ". until the output layer where the actual classification takes place. Since this project is about a binary classification task, a sigmoid activation function is used. Furthermore, since the target vector containing the labels is a binary 1D vector. In a multi-class scenario, the target vector would have needed to be one-hot encoded and the number of neurons would be n classes with a softmax activation function as an alternate option. \n",
    "\n",
    "Output layer (last fully connected layer)\n",
    "\n",
    "output = Dense (1, activation='sigmoid', name='output')(<penultimate_layer>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Model 1 Simple LSTM </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM or 1D convolutions can be used separately or together for the URL classification task. In any case before arriving to the output layer, it is very common to add a few fully connected hidden layers.  Finally, in every architecture the model has to be compiled while defining the optimizer and parameters such as learning rate to train the model in an iterative fashion as well as the loss function that quantifies how well the model is performing at each iteration. \n",
    "\n",
    "This is a simple one LSTM layer architecture which uses sigmoid as the activation function and Binary cross entropy for loss function. Dropout refers to ignoring units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random. By “ignoring”, I mean these units are not considered during a particular forward or backward pass. This is done to prevent over-fitting. \n",
    "\n",
    "** <font color='Purple'>Model features: </font> **\n",
    "1. **Activation function **: Sigmoid. \n",
    "2. **Loss Function** binary_crossentropy\n",
    "3. **Number of Epochs** 5\n",
    "4. **Optimizer Adam **: is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.\n",
    "\n",
    "LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n",
    "\n",
    "All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.bioinf.jku.at/publications/older/2604.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why we need an Optmizer and what is Adam Optimizer\n",
    "Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. Stochastic gradient descent maintains a single learning rate (termed alpha) for all weight updates and the learning rate does not change during training.\n",
    "Instead of adapting the parameter learning rates based on the average first moment (the mean) as in RMSProp, Adam also makes use of the average of the second moments of the gradients (the uncentered variance).\n",
    "\n",
    "Specifically, the algorithm calculates an exponential moving average of the gradient and the squared gradient, and the parameters beta1 and beta2 control the decay rates of these moving averages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are loss Functions:\n",
    "Loss functions are helpful to train a neural network. Given an input and a target, they calculate the loss, i.e difference between output and target variable.  Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. **Cross-entropy** loss increases as the predicted probability diverges from the actual label. So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is an Activation function\n",
    "It is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).\n",
    "The Activation Functions can be basically divided into 2 types-\n",
    "\n",
    "1. Linear Activation Function\n",
    "\n",
    "2. Non-linear Activation Functions\n",
    "\n",
    "The main reason why we use <font color='blue'> sigmoid function </font> is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Simple LSTM\n",
    "def simple_lstm(max_len=100, emb_dim=32, max_vocab_len=100, lstm_output_size=32, W_reg=regularizers.l2(1e-4)):\n",
    "    # Input\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    \n",
    "    # Embedding layer\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "                dropout=0.2, W_regularizer=W_reg)(main_input) \n",
    "\n",
    "    \n",
    "    # LSTM layer\n",
    "    lstm = LSTM(lstm_output_size)(emb)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    # Output layer (last fully connected layer)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(lstm)\n",
    "\n",
    "    # Compile model and define optimizer\n",
    "    model = Model(input=[main_input], output=[output])\n",
    "    \n",
    "    sgd= SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7498/7498 [==============================] - 47s 6ms/step - loss: 0.6194 - acc: 0.7457\n",
      "Epoch 2/5\n",
      "7498/7498 [==============================] - 47s 6ms/step - loss: 0.5352 - acc: 0.7559\n",
      "Epoch 3/5\n",
      "7498/7498 [==============================] - 45s 6ms/step - loss: 0.5023 - acc: 0.7593\n",
      "Epoch 4/5\n",
      "7498/7498 [==============================] - 45s 6ms/step - loss: 0.4653 - acc: 0.7769\n",
      "Epoch 5/5\n",
      "7498/7498 [==============================] - 45s 6ms/step - loss: 0.4419 - acc: 0.8022\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "\n",
      "Final Cross-Validation Accuracy 0.8156 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit model and Cross-Validation, ARCHITECTURE 1 SIMPLE LSTM\n",
    "nb_epoch = 5\n",
    "batch_size = 32\n",
    "\n",
    "model = simple_lstm()\n",
    "model.fit(X_train, target_train, nb_epoch=nb_epoch, batch_size=batch_size)\n",
    "loss, accuracy = model.evaluate(X_test, target_test, verbose=1)\n",
    "print('\\nFinal Cross-Validation Accuracy', accuracy, '\\n')\n",
    "#print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> Final Cross-Validation Accuracy 81.56% for 5 epoch and batch_size of 32</font>\n",
    "\n",
    "Total input is 10,000 URL and sample training set is 7498. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Model Summary </font>\n",
    "\n",
    "The below step helps determine what are the layers in this model and how each of the laters are connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 100, 71)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 96, 128)      45568       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 96, 128)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 48, 128)      0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 46, 196)      75460       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 46, 196)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 23, 196)      0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 21, 256)      150784      max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 21, 256)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 10, 256)      0           dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 200)      285600      max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 1)        201         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10)           0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10)           0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 200, 10)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 10, 200)      0           repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 10, 200)      0           bidirectional_2[0][0]            \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 200)          0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 200)          0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200)          0           dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            402         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 558,015\n",
      "Trainable params: 558,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Model 2 Implementing Convolutional Neural Networks </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intro to  Convolutional Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four main operations in the ConvNet shown in Figure above:\n",
    "\n",
    "Convolution\n",
    "\n",
    "Non Linearity (ReLU) in my implementation I use ELU instead of ReLU\n",
    "\n",
    "Pooling or Sub Sampling\n",
    "\n",
    "Classification (Fully Connected Layer)\n",
    "\n",
    "To prevent Overfitting I use a DropOutLayer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Each convolution layer is individually called and ELU is used as an activation function \n",
    "On the final dense later the activation function is sigmoid.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_fully(max_len=100, emb_dim=32, max_vocab_len=100, W_reg=regularizers.l2(1e-4)):\n",
    "    # Input\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    # Embedding layer\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "                W_regularizer=W_reg)(main_input) \n",
    "    emb = Dropout(0.25)(emb)\n",
    "\n",
    "    def sum_1d(X):\n",
    "        return K.sum(X, axis=1)\n",
    "    def get_conv_layer(emb, kernel_size=5, filters=256):\n",
    "        # Conv layer\n",
    "        conv = Convolution1D(kernel_size=kernel_size, filters=filters, \\\n",
    "                     border_mode='same')(emb)\n",
    "        conv = ELU()(conv)\n",
    "\n",
    "        conv = Lambda(sum_1d, output_shape=(filters,))(conv)\n",
    "        #conv = BatchNormalization(mode=0)(conv)\n",
    "        conv = Dropout(0.5)(conv)\n",
    "        return conv\n",
    "        \n",
    "    # Multiple Conv Layers\n",
    "    \n",
    "    # calling custom conv function from above\n",
    "    conv1 = get_conv_layer(emb, kernel_size=2, filters=256)\n",
    "    conv2 = get_conv_layer(emb, kernel_size=3, filters=256)\n",
    "    conv3 = get_conv_layer(emb, kernel_size=4, filters=256)\n",
    "    conv4 = get_conv_layer(emb, kernel_size=5, filters=256)\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    merged = concatenate([conv1,conv2,conv3,conv4], axis=1)\n",
    "\n",
    "    hidden1 = Dense(1024)(merged)\n",
    "    hidden1 = ELU()(hidden1)\n",
    "    hidden1 = BatchNormalization(mode=0)(hidden1)\n",
    "    hidden1 = Dropout(0.5)(hidden1)\n",
    "\n",
    "    hidden2 = Dense(1024)(hidden1)\n",
    "    hidden2 = ELU()(hidden2)\n",
    "    hidden2 = BatchNormalization(mode=0)(hidden2)\n",
    "    hidden2 = Dropout(0.5)(hidden2)\n",
    "    \n",
    "    # Output layer (last fully connected layer)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(hidden2)\n",
    "\n",
    "    # Compile model and define optimizer\n",
    "    model = Model(input=[main_input], output=[output])\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Characteristics\n",
    "1. 4 Fully connected layers with 2 dense layers.  \n",
    "2. Activation function used is **sigmoid** on the final dense later.\n",
    "3. Optimizer in used is **Adam**.\n",
    "4. Loss function in use **Binary Cross entropy**. \n",
    "5. With 5 Epocs and a batch size of 32. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are loss Functions:\n",
    "Loss functions are helpful to train a neural network. Given an input and a target, they calculate the loss, i.e difference between output and target variable.  Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7498/7498 [==============================] - 22s 3ms/step - loss: 0.8856 - acc: 0.5755\n",
      "Epoch 2/5\n",
      "7498/7498 [==============================] - 22s 3ms/step - loss: 0.6987 - acc: 0.6683\n",
      "Epoch 3/5\n",
      "7498/7498 [==============================] - 22s 3ms/step - loss: 0.6522 - acc: 0.7053\n",
      "Epoch 4/5\n",
      "7498/7498 [==============================] - 21s 3ms/step - loss: 0.5819 - acc: 0.7429\n",
      "Epoch 5/5\n",
      "7498/7498 [==============================] - 21s 3ms/step - loss: 0.5843 - acc: 0.7445\n",
      "2500/2500 [==============================] - 2s 880us/step\n",
      "\n",
      "Final Cross-Validation Accuracy 0.8068 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit model and Cross-Validation, ARCHITECTURE 3 CONV + FULLY CONNECTED\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "model = conv_fully()\n",
    "model.fit(X_train, target_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = model.evaluate(X_test, target_test, verbose=1)\n",
    "\n",
    "print('\\nFinal Cross-Validation Accuracy', accuracy, '\\n')\n",
    "#print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> Final Cross-Validation Accuracy 80.58% for 5 epoch and batch_size of 32</font>\n",
    "\n",
    "Total input is 10,000 URL and sample training set is 7498. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Model Summary </font>\n",
    "The below step helps determine what are the layers in this model and how each of the laters are connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 100, 32)      3200        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 100, 32)      0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 100, 256)     16640       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 100, 256)     24832       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 100, 256)     33024       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 100, 256)     41216       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_13 (ELU)                    (None, 100, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_14 (ELU)                    (None, 100, 256)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_15 (ELU)                    (None, 100, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_16 (ELU)                    (None, 100, 256)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 256)          0           elu_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 256)          0           elu_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 256)          0           elu_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 256)          0           elu_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 256)          0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 256)          0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 256)          0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 256)          0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1024)         0           dropout_22[0][0]                 \n",
      "                                                                 dropout_23[0][0]                 \n",
      "                                                                 dropout_24[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         1049600     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "elu_17 (ELU)                    (None, 1024)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1024)         4096        elu_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1024)         0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         1049600     dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_18 (ELU)                    (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1024)         4096        elu_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1024)         0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            1025        dropout_27[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,227,329\n",
      "Trainable params: 2,223,233\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model to Disk**\n",
    "\n",
    "The below function and stpes help save model to disk and use later against a diff dataset for test or verificaiton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERAL save model to disk function!\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    #have h5py installed\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deeplearning_1DConv\"\n",
    "save_model(path + model_name + \".json\", path + model_name + \".h5\")\n",
    "#model = load_model(path + model_name + \".json\", path + model_name + \".h5\")\n",
    "#print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Model 3  Implementing Bi-directional LSTM and CNN <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bidirectional LSTMs are an extension of traditional LSTMs that can improve model performance on sequence classification problems. It involves duplicating the first recurrent layer in the network so that there are now two layers side-by-side, then providing the input sequence as-is as input to the first layer and providing a reversed copy of the input sequence to the second.\n",
    "The use of bidirectional LSTMs may not make sense for all sequence prediction problems, but can offer some benefit in terms of better results to those domains where it is appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 100, 71)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 96, 128)      45568       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 96, 128)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 48, 128)      0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 46, 196)      75460       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 46, 196)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 23, 196)      0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 21, 256)      150784      max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 21, 256)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 10, 256)      0           dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 200)      285600      max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 1)        201         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10)           0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10)           0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 200, 10)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 10, 200)      0           repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 10, 200)      0           bidirectional_2[0][0]            \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 200)          0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 200)          0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200)          0           dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            402         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 558,015\n",
      "Trainable params: 558,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Layer,initializers,Flatten,RepeatVector,Permute\n",
    "from keras.layers.merge import Multiply\n",
    "    \n",
    "def binarize(x, sz=71):\n",
    "    return tf.to_float(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1))\n",
    "\n",
    "\n",
    "def binarize_outshape(in_shape):\n",
    "    return in_shape[0], in_shape[1], 71\n",
    "filter_length = [5, 3, 3]\n",
    "nb_filter = [128, 196, 256 ]\n",
    "pool_length = 2\n",
    "\n",
    "# sentence input\n",
    "in_sentence = Input(shape=(max_len,), dtype='int64')\n",
    "# char indices to one hot matrix, 1D sequence to 2D \n",
    "embedded = Lambda(binarize, output_shape=binarize_outshape)(in_sentence)\n",
    "# embedded: encodes sentence\n",
    "for i in range(len(nb_filter)):\n",
    "    embedded = Conv1D(filters=nb_filter[i],\n",
    "                      kernel_size=filter_length[i],\n",
    "                      padding='valid',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='glorot_normal',\n",
    "                      strides=1)(embedded)\n",
    "    embedded = Dropout(0.2)(embedded)\n",
    "    embedded = MaxPooling1D(pool_size=pool_length)(embedded)\n",
    "bi_lstm_sent = \\\n",
    "    Bidirectional(LSTM(100, return_sequences=True, dropout=0.15, recurrent_dropout=0.15, implementation=0))(embedded)\n",
    "\n",
    "\n",
    "    \n",
    "# compute importance for each step\n",
    "attention = TimeDistributed(Dense(1, activation='tanh'))(bi_lstm_sent) \n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = RepeatVector(200)(attention)\n",
    "attention = Permute([2, 1])(attention)    \n",
    "    \n",
    "\n",
    "# apply the attention \n",
    "sent_representation = Multiply()([bi_lstm_sent, attention])\n",
    "sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "    \n",
    "    \n",
    "# sent_encode = merge([forward_sent, backward_sent], mode='concat', concat_axis=-1)\n",
    "sent_encode = Dropout(0.4)(sent_representation)\n",
    "sent_encode = Activation(\"relu\")(sent_encode)\n",
    "sent_encode = Dense(units=2)(sent_encode)\n",
    "sent_encode = Activation(\"softmax\")(sent_encode)\n",
    "\n",
    "# sentence encoder\n",
    "model = Model(inputs=in_sentence, outputs=sent_encode)\n",
    "\n",
    "model.summary()\n",
    "#model = utils.make_parallel(model, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model features\n",
    "1. 3 convolution layers and one Bi-directional LSTM later \n",
    "2. Each layer uses a combination of softmax and relu activation function\n",
    "3. Optimizer in used is Adam.\n",
    "4. Loss function implemented in this model is sparse categorical crossentropy. \n",
    "5. With 5 Epocs and a batch size of 32, Final Cross-Validation Accuracy 84.56\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam()\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['sparse_categorical_accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7498/7498 [==============================] - 22s 3ms/step - loss: 0.4843 - acc: 0.7787\n",
      "Epoch 2/5\n",
      "7498/7498 [==============================] - 21s 3ms/step - loss: 0.4253 - acc: 0.8078\n",
      "Epoch 3/5\n",
      "7498/7498 [==============================] - 22s 3ms/step - loss: 0.3539 - acc: 0.8528\n",
      "Epoch 4/5\n",
      "7498/7498 [==============================] - 22s 3ms/step - loss: 0.2942 - acc: 0.8864\n",
      "Epoch 5/5\n",
      "7498/7498 [==============================] - 22s 3ms/step - loss: 0.2409 - acc: 0.9098\n",
      "2500/2500 [==============================] - 2s 863us/step\n",
      "\n",
      "Final Cross-Validation Accuracy 0.8456 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, target_train, epochs=5, batch_size=32)\n",
    "loss, accuracy = model.evaluate(X_test, target_test, verbose=1)\n",
    "\n",
    "print('\\nFinal Cross-Validation Accuracy', accuracy, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='green'> Final Cross-Validation Accuracy 84.56% for 5 epoch and batch_size of 32</font>\n",
    "\n",
    "Total input is 10,000 URL and sample training set is 7498. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Model Summary </font>\n",
    "The below step helps determine what are the layers in this model and how each of the laters are connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 100, 71)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 96, 128)      45568       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 96, 128)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 48, 128)      0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 46, 196)      75460       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 46, 196)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 23, 196)      0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 21, 256)      150784      max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 21, 256)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 10, 256)      0           dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 200)      285600      max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 1)        201         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10)           0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10)           0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 200, 10)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 10, 200)      0           repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 10, 200)      0           bidirectional_2[0][0]            \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 200)          0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 200)          0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200)          0           dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            402         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 558,015\n",
      "Trainable params: 558,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Results </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve is created by plotting the **true positive rate (TPR) ** against the **false positive rate (FPR)** at various threshold settings. The true-positive rate is also known as **sensitivity, recall or probability  of detection ** in machine learning. The false-positive rate is also known as the  ** fall-out or probability of false alarm ** and can be calculated as (1 − specificity)\n",
    "**ROC analysis ** provides tools to select possibly optimal models and to discard suboptimal ones independently from (and prior to specifying) the cost context or the class distribution. ROC analysis is related in a direct and natural way to cost/benefit analysis of diagnostic decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below verification is done on the **BiDirectional LSTM** model and the ROC curve indicates a higher false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1312e0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "pred = model.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(target_test, pred[:,1], pos_label=1)\n",
    "auc_m = metrics.auc(fpr, tpr)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',lw=lw, label='ROC curve (area = %0.4f)' % auc_m)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC - URL detection Bi-Directional LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the above we also use the F1 score, AUC and accuracy metrics to determine the efficiency of the model implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistical analysis of binary classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the **precision p** and the **recall r** of the test to compute the score: \n",
    "\n",
    "**Precision** is the number of correct positive results divided by the number of all positive results returned by the classifier, \n",
    "\n",
    "**Recall** is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive). \n",
    "\n",
    "The **F1 score** is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"f.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** is a description of random errors, a measure of statistical variability.\n",
    "\n",
    "**Accuracy** has two definitions:\n",
    "\n",
    "  * More commonly, it is a description of systematic errors, a measure of statistical bias; as these cause a difference between a result and a \"true\" value, ISO calls this trueness.\n",
    "\n",
    "  * Alternatively, ISO defines accuracy as describing a combination of both types of observational error above (random and systematic), so high accuracy requires both high precision and high trueness.\n",
    "\n",
    "In simplest terms, given a set of data points from repeated measurements of the same quantity, the set can be said to be precise if the values are close to each other, while the set can be said to be accurate if their average is close to the true value of the quantity being measured. The two concepts are independent of each other, so a particular set of data can be said to be either accurate, or precise, or both, or neither."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"roc.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 =  0.659010600707 acc =  0.8456 auc= 0.863376439579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "f1 = metrics.f1_score(target_test, pred[:,1]>0.5)\n",
    "acc = metrics.accuracy_score(target_test, pred[:,1]>0.5)\n",
    "print (\"f1 = \", f1, \"acc = \", acc, \"auc=\" , auc_m)\n",
    "#print (\"test confusion matrix\\n\" , confusion_matrix(target_test, pred[:,1]>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the latest model the \n",
    "\n",
    "  * **F1 score is  <font color='green'>0.65 </font> **\n",
    "  * **Accuracy is  <font color='green'>84.56 </font> **\n",
    "  * **AUC is <font color='green'>0.86</font> **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Prediction </font>\n",
    "In contrast to more traditional Machine Learning, where preprocessing and/or feture engineering can be quite tedious to transform a new URL into feature vector space, it's quite straight forward in the approach proposed here.\n",
    "\n",
    "** <font color='purple'>Steps to test the model </font>**\n",
    "1.\tConvert raw URL string in list of lists where characters that are contained in \"printable\" are stored encoded as integer.\n",
    "\n",
    "2.\tCut URL string at max_len or pad with zeros if shorter\n",
    "\n",
    "3.\tMake a new prediction with trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_predict_o = ['wikipedia.com',\n",
    "             'google.com',\n",
    "             'pakistanifacebookforever.com',\n",
    "             'www.radsport-voggel.de',\n",
    "             'ahrenhei.without-transfer.ru',\n",
    "             'www.itidea.it',\n",
    "             'stackoverflow.com',\n",
    "             'dzone.com',\n",
    "            'keras.io',\n",
    "             'www.tiktik.co.il']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions of X:  (1, 100) Vector dimension of target:  (9998,)\n"
     ]
    }
   ],
   "source": [
    "# Initial Data Preparation URL\n",
    "\n",
    "# Step 1: Convert raw URL string in list of lists where characters that are contained in \"printable\" are stored encoded as integer \n",
    "url_int_tokens = [[printable.index(x) + 1 for x in url if x in printable] for url in X_predict_o]\n",
    "\n",
    "# Step 2: Cut URL string at max_len or pad with zeros if shorter\n",
    "max_len=100\n",
    "X1 = sequence.pad_sequences(url_int_tokens, maxlen=max_len)\n",
    "#print(X1)\n",
    "# Step 3: Extract labels form df to numpy array\n",
    "target = np.array(df.malicious)\n",
    "\n",
    "print('Matrix dimensions of X: ', X.shape, 'Vector dimension of target: ', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikipedia.com</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google.com</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakistanifacebookforever.com</td>\n",
       "      <td>0.064834</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.radsport-voggel.de</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahrenhei.without-transfer.ru</td>\n",
       "      <td>0.042111</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>www.itidea.it</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stackoverflow.com</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dzone.com</td>\n",
       "      <td>0.007869</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>keras.io</td>\n",
       "      <td>0.007861</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www.tiktik.co.il</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           site     score prediction\n",
       "0                 wikipedia.com  0.007914      False\n",
       "1                    google.com  0.007872      False\n",
       "2  pakistanifacebookforever.com  0.064834      False\n",
       "3        www.radsport-voggel.de  0.008443      False\n",
       "4  ahrenhei.without-transfer.ru  0.042111      False\n",
       "5                 www.itidea.it  0.008915      False\n",
       "6             stackoverflow.com  0.009805      False\n",
       "7                     dzone.com  0.007869      False\n",
       "8                      keras.io  0.007861      False\n",
       "9              www.tiktik.co.il  0.009828      False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd1 = model.predict(X1)\n",
    "dfn = pd.DataFrame(columns=('site', 'score', 'prediction'))\n",
    "pd.set_option('max_colwidth',500)    \n",
    "for i in range(len(X_predict_o)):\n",
    "    a = [X_predict_o[i],  prd1[i,1],prd1[i,1]>0.5 ]\n",
    "    dfn.loc[i] = a\n",
    "dfn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** As noted from above the model is successfully able to predict for the given test test ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> References:</font>\n",
    "\n",
    "Malicious URL Detection using Machine Learning\n",
    "   \n",
    "   https://arxiv.org/pdf/1701.07179.pdf\n",
    "\n",
    "Learning a URL Representation with Deep Learning for Malicious URL Detection\n",
    "\n",
    "   https://arxiv.org/pdf/1802.03162.pdf\n",
    "\n",
    "Expose A Character-Level Convolutional Neural Network with Embedding For Detecting Malicious URLs\n",
    "\n",
    "  https://arxiv.org/pdf/1702.08568.pdf\n",
    "\n",
    "Word2Vec Embedding\n",
    "    \n",
    "  https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "Activation Function\n",
    " \n",
    "   https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
    "\n",
    "Convolution Neural Networks\n",
    "\n",
    "   https://wiki.tum.de/display/lfdv/Recurrent+Neural+Networks+-+Combination+of+RNN+and+CNN\n",
    "   \n",
    "   https://github.com/nikbearbrown/NEU_COE/tree/master/Deep_Learning/CNNs\n",
    "   \n",
    "RNN\n",
    "\n",
    "  https://github.com/nikbearbrown/NEU_COE/tree/master/Deep_Learning/RNNs/ \n",
    "    \n",
    "\n",
    "LSTM\n",
    "\n",
    "  https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/\n",
    "\n",
    "Embedding Layers\n",
    " \n",
    " https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12/\n",
    "    \n",
    " Metrics\n",
    " \n",
    "   https://en.wikipedia.org/wiki/F1_score\n",
    "   \n",
    "   https://en.wikipedia.org/wiki/Accuracy_and_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Licenses </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the document by Lakshmi Peri is licensed under the MIT License https://opensource.org/licenses/MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is licensed under the Creative Commons Attribution 3.0 United States License. To view a copy of this license, visit http://creativecommons.org/licenses/by/3.0/us/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
